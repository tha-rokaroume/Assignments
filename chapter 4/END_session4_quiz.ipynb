{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END_session4_quiz.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dad734e-d1a3-4e52-82bb-831ce5c8af46"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 10 #size of the hidden layer\n",
        "Time_steps = 10 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "\n",
        "  return (1/(1+np.exp(-x))) # write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return y * (1-y) # write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x) # write your code here\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1-y*y# write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77g-cwR8SrUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d29a7a-d3d0-42f9-a3bd-ff6cd8df923b"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcERFzsRSta4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d67a03-f9e4-4aa4-f028-db58ecb7b6ad"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0v87hVySthC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60828856-15b1-4ee2-fa2d-43c16648142e"
      },
      "source": [
        "np.round(tanh(dsigmoid(sigmoid(0))),5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24492"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUS8AXPJStoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b2f868-a89f-426d-bb0e-bc2c838264bc"
      },
      "source": [
        "np.round(dtanh(tanh(dsigmoid(sigmoid(0)))),5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.94001"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 5\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size# write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_o\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "\n",
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)   # write your code here\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v) # write your code here\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)   # write your code here\n",
        "\n",
        "    C = f*C_prev + i*C_bar # write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v) # write your code here\n",
        "    h = o * tanh(C) # write your code here\n",
        "\n",
        "    v =  np.dot(p.W_v.v, h) +  p.b_v.v   # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v) + 1e-8) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 6\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrLw_BzS_XBB",
        "outputId": "782840e2-542c-4733-aa80-5ce05a2e34ad"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 7 \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8aLo6mC-xT-",
        "outputId": "a846a8b6-07de-4a9e-9c86-068fd7762403"
      },
      "source": [
        "\n",
        "print(z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(85, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDowyMPY-xYg",
        "outputId": "73b7c830-637e-4971-9123-7164b778ded7"
      },
      "source": [
        "print(np.sum(z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ujAGiTY-xcs",
        "outputId": "27a99667-d9e0-48bc-a36d-27707ec91c34"
      },
      "source": [
        "print(np.sum(f))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        #idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        idx = np.random.choice(range(X_size))\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "e6923204-1b28-43ad-a606-63e6a76056fb"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            " pdhV1il5avumN5p-V;e)wkAk,rWkkc:eN1w6hUeF“ R:(wJPjzjL FKPYDoP)4y\n",
            "6c\n",
            "�-UGkM5N:\"GEn0blv2W\n",
            "uEmRLRaKV\n",
            "M,T:AxU87MC0d?yuk)?5WIArPfkiczO.Gblbkc,Fgj“t“uae?ADV-R\"Kg'c\"K2ePoTfg\n",
            "�crHfdFShA)I\n",
            "NUY30qILCA,dL)–gfz'OL \n",
            "----\n",
            "iter 49900, loss 20.603086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 8\n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}